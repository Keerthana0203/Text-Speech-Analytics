{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#3.Accessing Text Corpora using NLTK in Python"
      ],
      "metadata": {
        "id": "uKBRrxk2tai2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gDc5pt_jc2_",
        "outputId": "8377bb67-38a7-4e5d-861e-653288fe4ccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available files in Gutenberg Corpus:\n",
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
            "\n",
            "Text of 'shakespeare-hamlet.txt':\n",
            "[The Tragedie of Hamlet by William Shakespeare 1599]\n",
            "\n",
            "\n",
            "Actus Primus. Scoena Prima.\n",
            "\n",
            "Enter Barnardo and Francisco two Centinels.\n",
            "\n",
            "  Barnardo. Who's there?\n",
            "  Fran. Nay answer me: Stand & vnfold\n",
            "your selfe\n",
            "\n",
            "   Bar. Long liue the King\n",
            "\n",
            "   Fran. Barnardo?\n",
            "  Bar. He\n",
            "\n",
            "   Fran. You come most carefully vpon your houre\n",
            "\n",
            "   Bar. 'Tis now strook twelue, get thee to bed Francisco\n",
            "\n",
            "   Fran. For this releefe much thankes: 'Tis bitter cold,\n",
            "And I am sicke at heart\n",
            "\n",
            "   Barn. Haue you had quiet Guard?\n",
            "  Fran. Not...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "# Download the Gutenberg corpus (if not already downloaded)\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "def access_gutenberg_corpus():\n",
        "    # List available files in the Gutenberg corpus\n",
        "    print(\"Available files in Gutenberg Corpus:\")\n",
        "    print(gutenberg.fileids())\n",
        "\n",
        "    # Access and print the text of a specific document in the corpus\n",
        "    document_name = 'shakespeare-hamlet.txt'\n",
        "    document_text = gutenberg.raw(document_name)\n",
        "    print(f\"\\nText of '{document_name}':\\n{document_text[:500]}...\")\n",
        "\n",
        "def main():\n",
        "    # Access the Gutenberg corpus\n",
        "    access_gutenberg_corpus()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Write a function that finds the 50 most frequently occurring words of a text words. are not stop"
      ],
      "metadata": {
        "id": "4-bg7NDitapM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "def find_frequent_words(text, num_words=50):\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))  # Load English stop words\n",
        "    words = nltk.word_tokenize(text.lower())  # Tokenize text and lowercase words\n",
        "    filtered_words = [word for word in words if word not in stop_words]  # Filter stop words\n",
        "    fdist = FreqDist(filtered_words)  # Create frequency distribution\n",
        "    return fdist.most_common(num_words)  # Return the most common words\n",
        "\n",
        "# Example usage:\n",
        "text = \"This is a sample text with some common words and some less common words.\"\n",
        "frequent_words = find_frequent_words(text)\n",
        "print(frequent_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SctOiOn0sja4",
        "outputId": "5cd5e335-8794-4a74-a4fd-2f9d94887c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('common', 2), ('words', 2), ('sample', 1), ('text', 1), ('less', 1), ('.', 1)]\n"
          ]
        }
      ]
    }
  ]
}